{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenkumarprabakar18/Classnotes/blob/main/Scripts/Lab_test_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIfHw5fOxcQI",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16KyvWWg0Hgq"
      },
      "outputs": [],
      "source": [
        "data_path = \"https://raw.githubusercontent.com/Bits-Deep-Analytics/Predictive_analytics/dev/Data/PIMA/diabetes.csv\"\n",
        "dataset = pd.read_csv(data_path)\n",
        "display(dataset.head(10))\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "0T1MoU8u196J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "pgrxiY56ME0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_zeros = dataset[\n",
        "    (dataset['Glucose'] == 0)\n",
        "    | (dataset['BMI'] == 0)\n",
        "    | (dataset['Insulin'] == 0)\n",
        "    | (dataset['BloodPressure'] == 0)\n",
        "]\n",
        "print('N of examples with incomplete data = {}'.format(len(data_with_zeros)))"
      ],
      "metadata": {
        "id": "phKYCj6UMAqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#columns=['BMI', 'SkinThickness', 'Insulin', 'Glucose', 'BloodPressure' ]\n",
        "#for i in range(0, len(columns)):\n",
        "\n",
        " # dataset[columns[i]].replace(0, np.nan, inplace=True)\n",
        "  #dataset.dropna(subset=columns[i], inplace=True)\n",
        "#print(dataset.shape)\n",
        "  \n",
        "#Removing Zeros is almost removing half of the rows in the orginal dataset, the newshape is (392,9), and the model "
      ],
      "metadata": {
        "id": "IjSbWI0PB5Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.corr()"
      ],
      "metadata": {
        "id": "h9oq-nuh23IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "s=sns.heatmap(dataset.corr(), annot=True, cmap='RdBu', vmin=-1, vmax=1)\n",
        "s.set_yticklabels(s.get_yticklabels(), rotation=0, fontsize=12)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation=90, fontsize=12)\n",
        "plt.title(\"Correlation Heat Map\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jr4HdpHY3B6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar=StandardScaler()\n",
        "scaled_dataset=scalar.fit_transform(dataset)\n",
        "scaled_dataset\n"
      ],
      "metadata": {
        "id": "JM6rYq_T30JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pca= PCA()\n",
        "pca.fit(scaled_dataset)\n",
        "#The below code shows how much variance is explained by each component\n",
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "DbAt2Nbx3i3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(range(1,10), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle=\"--\" )\n",
        "plt.title(\"Explained variance by Components\")\n",
        "plt.xlabel(\"Number of components\")\n",
        "plt.ylabel(\"Cumulative Explained variance\")\n",
        "#6 components explain 90% of the variance"
      ],
      "metadata": {
        "id": "oRRRNuQ84k2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=dataset.loc[:,dataset.columns!='Outcome']\n",
        "y=dataset.loc[:,dataset.columns=='Outcome']\n",
        "x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "1wqYJkQ-6JfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps=[('Scaling', StandardScaler()), ('Reducing_dimension', PCA(n_components=0.90)), ('Modelling', LogisticRegression())]\n",
        "pipeline=Pipeline(steps)\n",
        "pipeline.fit(x_train,np.ravel(y_train))\n",
        "y_pred1=pipeline.predict(x_test)\n",
        "acc=metrics.accuracy_score(y_true=y_test, y_pred=y_pred1)\n",
        "c_matrix=metrics.confusion_matrix(y_true=y_test, y_pred=y_pred1)\n",
        "print(\"Accuracy is\", acc)\n",
        "print(c_matrix)\n",
        "                   "
      ],
      "metadata": {
        "id": "_Ux2xWW04lJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision1=round(metrics.precision_score(y_true=y_test, y_pred=y_pred1)*100,2)\n",
        "recall1=round(metrics.recall_score(y_true=y_test, y_pred=y_pred1)*100,2)\n",
        "print(\"Precision is \", precision1)\n",
        "print(\"Recall is\", recall1)\n"
      ],
      "metadata": {
        "id": "Al0RUwtvAJAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After checking different possibilities, we found n_neighbours=7, and minkowski distance of p=2\n",
        "steps=[('Scaling', StandardScaler()), ('Reducing_dimension', PCA(n_components=0.90)), ('Modelling', KNeighborsClassifier(n_neighbors= 7, metric='minkowski', p=2 ))]\n",
        "pipeline=Pipeline(steps)\n",
        "pipeline.fit(x_train,np.ravel(y_train))\n",
        "y_pred2=pipeline.predict(x_test)\n",
        "acc=metrics.accuracy_score(y_true=y_test, y_pred=y_pred2)\n",
        "c_matrix=metrics.confusion_matrix(y_true=y_test, y_pred=y_pred2)\n",
        "print(\"Accuracy is\", acc)\n",
        "print(c_matrix)"
      ],
      "metadata": {
        "id": "xufBfYhx_vos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision2=round(metrics.precision_score(y_true=y_test, y_pred=y_pred2)*100,2)\n",
        "recall2=round(metrics.recall_score(y_true=y_test, y_pred=y_pred2)*100,2)\n",
        "print(\"Precision is \", precision2)\n",
        "print(\"Recall is\", recall2)"
      ],
      "metadata": {
        "id": "3D66IP6wLUGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8dj-KCC4HlRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(0,9):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
        "  classifier=KNeighborsClassifier(n_neighbors= 5, metric='minkowski', p=2 )\n",
        "  classifier.fit(x_train, y_train)\n",
        "  y_prediction = classifier.predict(x_test)\n",
        "  cm=confusion_matrix(y_test, y_prediction)\n",
        "  acc=accuracy_score(y_test, y_prediction)\n",
        "  l.append(acc)\n",
        "\n",
        "avg=0\n",
        "sum=0\n",
        "for i in range(0,9):\n",
        "  sum+=l[i]\n",
        "avg=sum/len(l)\n",
        "print(avg)\n",
        "  "
      ],
      "metadata": {
        "id": "2ppros_BHlaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_lr = roc_auc_score(y_test, y_pred1)\n",
        "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred1)\n",
        "\n",
        "auc_knn = roc_auc_score(y_test, y_pred2)\n",
        "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred2)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f'AUC (Logistic Regression) = {auc_lr:.2f}')\n",
        "plt.plot(fpr_knn, tpr_knn, label=f'AUC (KNN) = {auc_knn:.2f}')\n",
        "\n",
        "plt.title('ROC Curve', size=20)\n",
        "plt.xlabel('False Positive Rate', size=14)\n",
        "plt.ylabel('True Positive Rate', size=14)\n",
        "plt.legend();\n",
        "roc_auc_score(y_test,y_pred1)\n",
        "roc_auc_score(y_test,y_pred2)"
      ],
      "metadata": {
        "id": "Dwtf8qvzHlh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7iR5oykM5Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "size= dataset.size\n",
        "# create the range of dataset\n",
        "rn = range(size)\n",
        "# to demonstrate how the data are split, we will create 3 and 5 folds.\n",
        "# KFold function has to be applied on the data and it returns an location (index) of the train and test samples.\n",
        "kf10 = KFold(n_splits=10, shuffle=False)\n",
        "for train_index, test_index in kf10.split(rn):\n",
        "    print(train_index, test_index)"
      ],
      "metadata": {
        "id": "YCrUwe7wHlln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pih9XdenHloT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eE2n5hVeHlq7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}